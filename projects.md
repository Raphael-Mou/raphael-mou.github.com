---
layout: page
permalink: /projects/index.html
title: Projects
---

# Research Projects

## <font color = #4183C4> Scene Recognition by Manifold Regularized Deep Architecture </font>
<img border="0" width="618" height="308" src="/images/SceneClassification.jpg"  class="floatpic">

Scene recognition has been widely studied to un-derstand visual information from the level of objects and their relationships. A manifold regularized deep architecture is studied for scene recognition task. The deep architecture exploits the structure information of images to learn deeply the effective feature layer by layer.

## <font color = #4183C4> Semi-Supervised Multi-task Learning for Scene Recognition </font>
<img border="0" width="618" height="308" src="/images/MultiTask.jpg"  class="floatpic">

In order to study the effects of image scale and redundant features on scene recognition task, we propose a multi-task model to integrate scene images of different resolutions. Meanwhile, building a model of sparse feature selection based manifold regularized (SFSMR) to select the optimal information and preserve the underlying manifold structure of data. Finally, we link the multi-task model and SFSMR and propose the semi-supervised learning method.

## <font color = #4183C4> Scene Parsing from An MAP Perspective </font>
<img border="0" width="618" height="308" src="/images/SceneParsing.jpg"  class="floatpic">

To gain a deeper scene parsing (what objects appear in a scene, where the objects are located and which scene category the image shows), an MAP based approach is researched. This approach considers the problem by combining classification perspectve and segmentation perspective and user can obtain a pixel-wise annotated result with our approach.

## <font color = #4183C4> Object or Background: Whose Call is It in Complicated Scene Classification? </font>
<img border="0" width="618" height="308" src="/images/What.jpg"  class="floatpic">

Base on the research of pixel-wise scene parsing, we are curious about one question: Object or background, which one is more important to determine the scene category. This project designs respectively two high-level semantic feaures to describe the object and background which appear in the scene. Then we study how these two high-level features influence the determination of scene category. Experiments show that background is a powerful factor for determination of scene category.

## <font color = #4183C4> Semantic Parsing of Video by Combining Frame Relevance and Label Propagation from Images  </font>
<img border="0" width="618" height="308" src="/images/VideoParsing.gif"  class="floatpic">

On this project, we focus on problem of video parsing. Due to the difficulty of manually labeling video, it is time consuming and requires many human labor. Recently, several pixel-wise labeled image datasets have been introduced in order to research the problem of semantic parsing of images and some approaches have achieved success to some extent based on these datasets. Inspirited by these datasets, with such massive pixel-wise label maps, is it possible to transfer or propagate such labels from images to videos? 

## <font color = #4183C4> Realtime 3D SLAM with RGB-D Sensor </font>
<img border="0" width="618" height="308" src="/images/rgb-dSlam.jpg"  class="floatpic">

Recently, some RGB-D sensors like Microsoft Kinect or Asus Xtion sensor that can provide both RGB color image and dense depth images become likely available. There are great expectations that such RGB-D sensors will provide a new way to parse indoor scenes using 3D perspective. In the first place, we are interseted in 3D mapping and localization using RGB-D sensors. Consequently I written some codes which are simple program and can perform realtime 3D SLAM. 